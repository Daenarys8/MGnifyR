% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/MGnifyR.R
\name{mgnify_query_json}
\alias{mgnify_query_json}
\title{Low level MGnify API handler}
\usage{
mgnify_query_json(client, path = "biomes", qopts = NULL,
  maxhits = 200, usecache = F, Debug = F)
}
\arguments{
\item{client}{MGnifyR client}

\item{path}{top level search point for the query. One of \code{biomes}, \code{samples}, \code{runs} etc.}

\item{qopts}{named list or vector containing options/filters to be URL encoded and appended to query as key/value pairs}

\item{maxhits}{Maxmium number of data entries to return. The actual number of hits returned may be higher than this value,
as this parameter only clamps after each full page is processed.}

\item{usecache}{Should successful queries be cached on disk locally? There are unresolved questions about whether this is
a sensible thing to do, but it remains as an option. It probably makes sense for single accession grabs, but not for
(filtered) queries - which are liable to change as new data is added to MGnify. Also caching only works for the first page.}

\item{Debug}{Should we print out lots of information while doing the grabbing?}
}
\value{
\code{list} of results after pagination is dealt with.
}
\description{
\code{mgnify_query_json} deals with handles the actual HTTP GET calls for the MGnifyR package, handling both pagination and local reuslt
caching. Although principally intended for internal MGnifyR use , it's exported for direct invocation.
}
